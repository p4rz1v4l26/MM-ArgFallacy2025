{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "base_data_path = Path('Dataset-textonly')\n",
    "base_data_path1 = Path('Dataset-afd-textonly')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mamkit.data.datasets import MMUSEDFallacy, InputMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to Download MMUSEDFallacy data\n",
    "\n",
    "mm_used_fallacy_loader = MMUSEDFallacy(\n",
    "    task_name='afc',              \n",
    "    input_mode=InputMode.TEXT_ONLY, \n",
    "    base_data_path=base_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mm_used_fallacy_loader = MMUSEDFallacy(\n",
    "    task_name='afd',  \n",
    "    input_mode=InputMode.TEXT_ONLY,  \n",
    "    base_data_path=base_data_path1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: Index(['filename', 'dialogue_id', 'fallacy', 'dialogue_start_time',\n",
      "       'dialogue_end_time', 'dialogue_indexes', 'dialogue_sentences',\n",
      "       'dialogue_tokens', 'dialogue_whisper_indexes', 'dialogue',\n",
      "       'snippet_start_time', 'snippet_end_time', 'snippet_indexes',\n",
      "       'snippet_sentences', 'snippet_tokens', 'snippet_whisper_indexes',\n",
      "       'snippet'],\n",
      "      dtype='object')\n",
      "Sample: 0    1984_07Oct_1\n",
      "1    1984_07Oct_1\n",
      "Name: filename, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load dataset.pkl\n",
    "pkl_path = \"Dataset-afd-textonly\\MMUSED-fallacy\\dataset.pkl\"\n",
    "with open(pkl_path, \"rb\") as f:\n",
    "    dataset = pickle.load(f)\n",
    "\n",
    "# Print keys and sample data\n",
    "print(f\"Keys: {dataset.keys()}\")\n",
    "print(f\"Sample: {dataset[list(dataset.keys())[0]][:2]}\")  # Print first 2 entries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fallacy\n",
      "AppealtoEmotion      800\n",
      "AppealtoAuthority    191\n",
      "AdHominem            149\n",
      "FalseCause            56\n",
      "Slipperyslope         46\n",
      "Slogans               36\n",
      "Name: count, dtype: int64\n",
      "                                   snippet_sentences            fallacy\n",
      "0  [And there are other ways of squeezing this bu...    AppealtoEmotion\n",
      "1  [And you let those people go with the guidelin...    AppealtoEmotion\n",
      "2  [In mine, I happen to believe in the people an...  AppealtoAuthority\n",
      "3  [That's why faith in the United States is pure...    AppealtoEmotion\n",
      "4  [That's why faith in the United States is pure...    AppealtoEmotion\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"fallacy\"].value_counts())  # Check distribution of fallacy labels\n",
    "print(dataset[[\"snippet_sentences\", \"fallacy\"]].head())  # View sample text & labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   snippet_sentences            fallacy\n",
      "0  And there are other ways of squeezing this bud...    AppealtoEmotion\n",
      "1  And you let those people go with the guideline...    AppealtoEmotion\n",
      "2  In mine, I happen to believe in the people and...  AppealtoAuthority\n",
      "3  That's why faith in the United States is pure ...    AppealtoEmotion\n",
      "4  That's why faith in the United States is pure ...    AppealtoEmotion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\waral\\AppData\\Local\\Temp\\ipykernel_7220\\3420496498.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"snippet_sentences\"] = df[\"snippet_sentences\"].apply(lambda x: \" \".join(x) if isinstance(x, list) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = dataset  \n",
    "\n",
    "# Keep only relevant columns\n",
    "df = df[[\"snippet_sentences\", \"fallacy\"]]\n",
    "\n",
    "# Convert list of sentences to a single string\n",
    "df[\"snippet_sentences\"] = df[\"snippet_sentences\"].apply(lambda x: \" \".join(x) if isinstance(x, list) else x)\n",
    "\n",
    "# Save cleaned dataset\n",
    "df.to_csv(\"cleaned_data/fallacy_dataset.csv\", index=False)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, \"snippet_sentences\"] = df[\"snippet_sentences\"].apply(lambda x: \" \".join(x) if isinstance(x, list) else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\waral\\AppData\\Local\\Temp\\ipykernel_7220\\1868929350.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, \"binary_label\"] = df[\"fallacy\"].apply(lambda x: \"Fallacy\" if pd.notna(x) else \"No Fallacy\")\n"
     ]
    }
   ],
   "source": [
    "df.loc[:, \"binary_label\"] = df[\"fallacy\"].apply(lambda x: \"Fallacy\" if pd.notna(x) else \"No Fallacy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_label\n",
      "Fallacy    1278\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"binary_label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "['AppealtoEmotion' 'AppealtoAuthority' 'FalseCause' 'Slogans' 'AdHominem'\n",
      " 'Slipperyslope']\n"
     ]
    }
   ],
   "source": [
    "print(df[\"fallacy\"].isna().sum())  # Count of NaN values\n",
    "print(df[\"fallacy\"].unique())      # Check unique values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
    "X = vectorizer.fit_transform(df[\"snippet_sentences\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\waral\\AppData\\Local\\Temp\\ipykernel_7220\\850748795.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, \"fallacy_label\"] = label_encoder.fit_transform(df[\"fallacy\"])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode fallacy labels\n",
    "label_encoder = LabelEncoder()\n",
    "df.loc[:, \"fallacy_label\"] = label_encoder.fit_transform(df[\"fallacy\"])\n",
    "\n",
    "# Convert text into TF-IDF features\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2), stop_words=\"english\")\n",
    "X = vectorizer.fit_transform(df[\"snippet_sentences\"])\n",
    "y = df[\"fallacy_label\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using LR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.62890625\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "        AdHominem       0.00      0.00      0.00        30\n",
      "AppealtoAuthority       1.00      0.03      0.05        39\n",
      "  AppealtoEmotion       0.63      1.00      0.77       160\n",
      "       FalseCause       0.00      0.00      0.00        11\n",
      "    Slipperyslope       0.00      0.00      0.00         9\n",
      "          Slogans       0.00      0.00      0.00         7\n",
      "\n",
      "         accuracy                           0.63       256\n",
      "        macro avg       0.27      0.17      0.14       256\n",
      "     weighted avg       0.54      0.63      0.49       256\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\waral\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\waral\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\waral\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\waral\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Train the classifier\n",
    "model = LogisticRegression(multi_class=\"ovr\", solver=\"liblinear\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./LR_model/logistic_regression_model.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(model, './LR_model/logistic_regression_model.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "\n",
    "#  Load Data\n",
    "df = pd.read_csv(\"Cleaned_data/fallacy_dataset.csv\")  \n",
    "df[\"text\"] = df[\"snippet_sentences\"].apply(lambda x: \" \".join(x) if isinstance(x, list) else x)  # Convert lists to strings\n",
    "df[\"label\"] = df[\"fallacy\"].astype(\"category\").cat.codes  # Convert fallacy names to numeric labels\n",
    "\n",
    "#  Train-Test Split\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(df[\"text\"], df[\"label\"], test_size=0.2, random_state=42)\n",
    "\n",
    "#  Load BERT Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "#  Tokenize Texts\n",
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=512)\n",
    "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True, max_length=512)\n",
    "\n",
    "#  Convert to Hugging Face Dataset Format\n",
    "train_dataset = Dataset.from_dict({\"input_ids\": train_encodings[\"input_ids\"], \"attention_mask\": train_encodings[\"attention_mask\"], \"labels\": train_labels.tolist()})\n",
    "test_dataset = Dataset.from_dict({\"input_ids\": test_encodings[\"input_ids\"], \"attention_mask\": test_encodings[\"attention_mask\"], \"labels\": test_labels.tolist()})\n",
    "\n",
    "#  Load Pretrained BERT Model for Classification\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=df[\"label\"].nunique())\n",
    "\n",
    "#  Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "#  Define Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "\n",
    "#  Train the Model\n",
    "trainer.train()\n",
    "\n",
    "#  Evaluate the Model\n",
    "predictions = trainer.predict(test_dataset)\n",
    "preds = np.argmax(predictions.predictions, axis=-1)\n",
    "\n",
    "#  Print Results\n",
    "print(\"Accuracy:\", accuracy_score(test_labels, preds))\n",
    "print(\"Classification Report:\\n\", classification_report(test_labels, preds, target_names=df[\"fallacy\"].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./bert_fallacy_model\")\n",
    "tokenizer.save_pretrained(\"./bert_fallacy_model\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
